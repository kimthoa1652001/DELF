# DELF

## Introduction
  Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which account for a large portion of what people like to photograph.Traditional image retrieval methods rely on hand-crafted features, such as color histograms, texture descriptors, and SIFT (Scale-Invariant Feature Transform) features. However, these methods are limited in their ability to capture the complex and high-dimensional visual content of an image. Recently, deep learning-based methods have been proposed for image retrieval, which has shown great potential for improving the accuracy and efficiency of image retrieval systems.
  For this project, we embarked on the work of cloning an available dataset named “ The Oxford Building Dataset”. This dataset consists of 5062 images collected from Flickr by searching for particular Oxford landmarks. The collection has been manually annotated to generate a comprehensive ground truth for 11 landmarks, each represented by 5 possible queries. This gives a set of 55 queries over which an object retrieval system can be evaluated. The Oxford Buildings dataset was created to benchmark object retrieval. While the images are of buildings, many incidental people appear in the images.
  
## Methodology
  
